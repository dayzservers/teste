
<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8">
  <title>NotÃ­cias em Destaque</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <h1>ğŸ“° NotÃ­cias em Destaque</h1>
    <p>Resumo automÃ¡tico das principais notÃ­cias da BBC Brasil</p>
  </header>

  <main>
    
    <article class="card">
      <h2>Levei 20 minutos para enganar ChatGPT e Gemini â€“ e os fiz contar mentiras sobre mim</h2>
      <p>CrÃ©dito, Serenity Strull/ Madeline Jett Talvez vocÃª jÃ¡ tenha ouvido que chatbots de inteligÃªncia artificial, como o ChatGPT, Ã s vezes inventam coisas. Isso Ã© um problema. Mas hÃ¡ uma nova questÃ£o que poucas pessoas conhecem â€” uma que pode ter consequÃªncias sÃ©rias para a sua capacidade de encontrar informaÃ§Ãµes precisas e atÃ© para a sua seguranÃ§a. Um nÃºmero crescente de pessoas descobriu um truque para fazer ferramentas de IA dizerem praticamente qualquer coisa que elas quiserem. Ã‰ tÃ£o fÃ¡cil que atÃ© uma crianÃ§a conseguiria fazer.</p>
      <a href="https://www.bbc.com/portuguese/articles/cy4w88ew21jo" target="_blank">Ler na BBC â†’</a>
    </article>
    
  </main>

  <footer>
    <p>Fonte: BBC Brasil â€¢ ConteÃºdo resumido automaticamente</p>
  </footer>
</body>
</html>
